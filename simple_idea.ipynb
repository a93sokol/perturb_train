{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2357a85-4d3f-4793-9b5b-a356c9cf75c0",
   "metadata": {},
   "source": [
    "## Simple perturbation prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef338e8d-6c1a-4e0f-95bd-489a295a13da",
   "metadata": {},
   "source": [
    "Below I introduce an experiment design allowing to perform perturbation modelling using of-the-shelf models and only scRNAseq data.\n",
    "\n",
    "0. Normalise as proposed in scGPT and split data into two batches with no class overlap.\n",
    "1. Predict perturbation type on per-cell basis. This gives some kind of assymmetric similarity (or divergence). Loop 0-1 to obtain multiple measures.\n",
    "2. Build divergence matrices providing context to every cell.\n",
    "3. As a baseline, predict gene expression perturbation AB from the profiles of perturbations A and B. Can be done either using multiregression model (simpler but slower) or a DL architecture (e.g. VAE).\n",
    "4. Assess the success of the synthetic profile using classifiers from (1).\n",
    "5. Introduce the divergence matrix context and assess whether it helps.\n",
    "6. Compare the designed matrix to external data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf26e58-960e-40d1-b160-be4876747e6f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96dfb0b1-2553-44d8-9069-aa4b381d7235",
   "metadata": {},
   "outputs": [],
   "source": [
    "del cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "be7da009-644e-4c15-a074-ab1671daf24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as scp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import catboost as cb\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28545cb6-f504-4523-8ea6-0e37ec165a9f",
   "metadata": {},
   "source": [
    "### Magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "2d1aad38-4497-4f8c-b5ed-c17b65b5fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BINS = 30\n",
    "N_ITER = 100\n",
    "TOP_N_GENES = 100\n",
    "TOP_N_DIVER = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c34cd4-4903-47d4-aeba-57aa5aff6e2b",
   "metadata": {},
   "source": [
    "### Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "579f1ded-ce0a-442a-9f46-aac212209692",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = scp.read_h5ad('./data/Norman_2019/norman_umi_go/perturb_processed.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "dc17e045-10e5-4a5f-853c-c02d17410346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "## Following the scGPT paper, we bin the genes within cell. \n",
    "\n",
    "def bin_nonzero_values(arr, num_bins):\n",
    "    # Filter out non-zero values\n",
    "    nonzero_vals = arr[arr != 0]\n",
    "    \n",
    "    # Calculate bin edges\n",
    "    bin_edges = np.linspace(nonzero_vals.min(), nonzero_vals.max(), num_bins)\n",
    "    \n",
    "    # Bin the values\n",
    "    binned_values = np.zeros_like(arr)\n",
    "    binned_nonzero = np.digitize(nonzero_vals, bin_edges)\n",
    "    binned_values[arr != 0] = binned_nonzero\n",
    "    \n",
    "    return binned_values\n",
    "\n",
    "# Example usage\n",
    "arr = np.random.randint(low=0, high=100, size=100)\n",
    "num_bins = 3\n",
    "binned_values = bin_nonzero_values(arr, num_bins)\n",
    "print(set(binned_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "6ff55295-12fe-41f9-b7f6-b122df4533cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scp.pp.normalize_total(adata, exclude_highly_expressed=True)\n",
    "scp.pp.log1p(adata)\n",
    "scp.pp.highly_variable_genes(adata, n_top_genes=TOP_N_GENES,subset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e7de02c3-4aa2-40cd-81e5-7d07ce966e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 91205/91205 [00:03<00:00, 27102.59it/s]\n"
     ]
    }
   ],
   "source": [
    "tempy = adata.X.toarray()\n",
    "\n",
    "for c in tqdm(range(adata.X.shape[0])):\n",
    "    tempy[c,:] = bin_nonzero_values(tempy[c,:], N_BINS)\n",
    "\n",
    "adata.X = sparse.csr_matrix(tempy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "2e7dfdec-6ecf-4033-b548-36e5cc16d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tempy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "52090a5e-fa6d-4b5f-b6cb-f5a165b2e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = adata.obs.condition.values.astype(str)\n",
    "X = adata.X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "dcff16ed-de02-4c3d-a230-b813e49926fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91205, 100)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c6c94-fc95-41d1-a5cb-e0761585a75d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▎                                                               | 2/100 [04:21<3:33:43, 130.86s/it]"
     ]
    }
   ],
   "source": [
    "unique_classes = np.unique(y)\n",
    "\n",
    "similarity_res = np.zeros(shape=(X.shape[0], N_ITER),dtype=object)\n",
    "\n",
    "for i in tqdm(range(N_ITER)):\n",
    "    # Split the unique classes into two sets\n",
    "    classes_train, _ = train_test_split(unique_classes, test_size=0.5, random_state=47+i)\n",
    "    \n",
    "    # Filter the data based on the selected classes for training and testing\n",
    "    curr_idx_mask = np.isin(y, classes_train)\n",
    "    X_train, y_train = X[curr_idx_mask], y[curr_idx_mask]\n",
    "    X_test, y_test = X[~curr_idx_mask], y[~curr_idx_mask]\n",
    "    idx = np.arange(X.shape[0])\n",
    "    curr_idx = idx[curr_idx_mask]\n",
    "    curr_idx_test = idx[~curr_idx_mask]\n",
    "    \n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                      test_size=0.2, \n",
    "                                                      random_state=42,\n",
    "                                                      )\n",
    "    \n",
    "    model = LGBMClassifier(verbose=-1, n_jobs=10)\n",
    "    \n",
    "    # Train the model with validation data\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='auc_mu')\n",
    "    \n",
    "                                                                        # # Create the CatBoost classifier\n",
    "                                                                        # model = CatBoostClassifier(verbose=True,thread_count=10,)\n",
    "                                                                        \n",
    "                                                                        # # Train the model\n",
    "                                                                        # model.fit(X_train, y_train, \n",
    "                                                                        #           eval_set=(X_val, y_val), \n",
    "                                                                        #           use_best_model=True)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    similarity_res[curr_idx_test, i] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a5ecc-8263-4fc7-9c77-b20ba6bd99aa",
   "metadata": {},
   "source": [
    "### Compute the divergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0832f85f-86b7-4dd3-ac12-987fd3114635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_probs(arr, n):\n",
    "    \"\"\"\n",
    "    Computes the top N frequent non-zero elements and their associated probabilities\n",
    "    in every row of a 2D NumPy array of type object.\n",
    "\n",
    "    Args:\n",
    "        arr (numpy.ndarray): A 2D NumPy array of type object.\n",
    "        n (int): The number of top frequent elements to consider.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two arrays:\n",
    "            - top_n_arr (numpy.ndarray): An array with shape (n_rows, n),\n",
    "              containing the top N frequent non-zero elements per row.\n",
    "            - probs_arr (numpy.ndarray): An array with shape (n_rows, n),\n",
    "              containing the probabilities of the associated top N non-zero elements.\n",
    "    \"\"\"\n",
    "    n_rows = arr.shape[0]\n",
    "    top_n_arr = np.full((n_rows, n), None, dtype=object)\n",
    "    probs_arr = np.full((n_rows, n), np.nan, dtype=np.float64)\n",
    "\n",
    "    for i, row in enumerate(arr):\n",
    "        non_zero_row = [x for x in row if x != 0]\n",
    "        counter = Counter(non_zero_row)\n",
    "        top_n_elements = [item for item, count in counter.most_common(n)]\n",
    "        probs = [count / sum(counter.values()) for item, count in counter.most_common(n)]\n",
    "\n",
    "        for j, element in enumerate(top_n_elements):\n",
    "            top_n_arr[i, j] = element\n",
    "            probs_arr[i, j] = probs[j]\n",
    "\n",
    "    return top_n_arr, probs_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f4287eeb-9d1a-4060-b23e-006929532ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_names = adata.var.gene_name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "358bede9-679c-474b-b806-0aef16484a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diverg = top_n_probs(similarity_res, TOP_N_DIVER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "bd02c8b3-ab45-40a8-b02d-2b99667cbc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 91205/91205 [00:00<00:00, 302502.87it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(diverg[0].shape[0])):\n",
    "    for j in range(TOP_N_DIVER):\n",
    "        if diverg[0][i][j] is not None:\n",
    "            diverg[0][i][j] = diverg[0][i][j].replace('+ctrl','').replace('ctrl+','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "616c7309-bb27-4d7e-94b0-c2b36587c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich_mtx = np.zeros(shape=(adata.obs.shape[0], TOP_N_GENES))\n",
    "for i in range(enrich_mtx.shape[0]):\n",
    "    for j in range(2):\n",
    "        if diverg[0][i][j] in gene_names:\n",
    "            enrich_mtx[i, diverg[0][i][j] == gene_names] = diverg[1][i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "082746d3-79a9-4171-8217-276e28e48350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91205, 100)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrich_mtx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "e2bbe032-abc0-476c-b255-cc579213f940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1944"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(enrich_mtx!=0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51280c3f-0b44-42e5-a6df-6be8e32dbd10",
   "metadata": {},
   "source": [
    "## Preparing data from the second part - first, naive without the divergences, then adding it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "c83cb040-3a31-4625-b26a-02dcb39a116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([i.translate(str.maketrans('', '', '+ctrl')) if ('+' in i and 'ctrl' in i) else i for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "50b3f8ee-7f5b-4948-8876-3c841c0185fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 16517/16517 [00:04<00:00, 3753.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 18928/18928 [00:05<00:00, 3253.59it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_classes = np.unique(y)\n",
    "classes_train, classes_test = train_test_split(unique_classes, test_size=0.5, random_state=47+i)\n",
    "\n",
    "# Filter the data based on the selected classes for training and testing\n",
    "curr_idx_mask = np.isin(y, classes_train)\n",
    "X_train, y_train = X[curr_idx_mask], y[curr_idx_mask]\n",
    "X_test, y_test = X[~curr_idx_mask], y[~curr_idx_mask]\n",
    "\n",
    "diverg_tr = enrich_mtx[curr_idx_mask]\n",
    "diverg_ts = enrich_mtx[~curr_idx_mask]\n",
    "\n",
    "double_pert_ids_tr = []\n",
    "for s in range(y_train.shape[0]):\n",
    "    if '+' in y_train[s] and 'ctrl' not in y_train[s]:\n",
    "        double_pert_ids_tr.append(s)\n",
    "\n",
    "double_pert_ids_ts = []\n",
    "for s in range(y_test.shape[0]):\n",
    "    if '+' in y_test[s] and 'ctrl' not in y_test[s]:\n",
    "        double_pert_ids_ts.append(s)\n",
    "\n",
    "\n",
    "# First for training\n",
    "dic = {}\n",
    "\n",
    "p2_train = []\n",
    "for dp_id in tqdm(double_pert_ids_tr):\n",
    "    c1, c2 = y_train[dp_id].split('+')\n",
    "    \n",
    "    if c1 in y_train and c2 in y_train:\n",
    "        \n",
    "        if c1 not in dic.keys():\n",
    "            dic[c1] = np.where(np.array(y_train)==c1)[0]\n",
    "        pos1 = np.random.choice(dic[c1])\n",
    "        \n",
    "        if c2 not in dic.keys():\n",
    "            dic[c2] = np.where(np.array(y_train)==c1)[0]\n",
    "        pos2 = np.random.choice(dic[c2])\n",
    "        \n",
    "        p2_train.append((pos1, pos2, dp_id))\n",
    "\n",
    "# Then for testing\n",
    "p2_test = []\n",
    "for dp_id in tqdm(double_pert_ids_ts):\n",
    "    c1, c2 = y_test[dp_id].split('+')\n",
    "    \n",
    "    if c1 in y_test and c2 in y_test:\n",
    "        \n",
    "        if c1 not in dic.keys():\n",
    "            dic[c1] = np.where(np.array(y_test)==c1)[0]\n",
    "        pos1 = np.random.choice(dic[c1])\n",
    "        \n",
    "        if c2 not in dic.keys():\n",
    "            dic[c2] = np.where(np.array(y_test)==c1)[0]\n",
    "        pos2 = np.random.choice(dic[c2])\n",
    "        \n",
    "        p2_test.append((pos1, pos2, dp_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "07f95921-753a-45ba-9149-248164c657c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 2920/2920 [00:00<00:00, 190312.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 6795/6795 [00:00<00:00, 168841.61it/s]\n"
     ]
    }
   ],
   "source": [
    "X2_train = np.zeros(shape=(len(p2_train),TOP_N_GENES*2+diverg_tr.shape[1]))\n",
    "Y2_train = np.zeros(shape=(len(p2_train),TOP_N_GENES))\n",
    "\n",
    "for i in tqdm(range(Y2_train.shape[0])):\n",
    "    X2_train[i,:TOP_N_GENES] = X[p2_train[i][0]]\n",
    "    X2_train[i,TOP_N_GENES:TOP_N_GENES*2] = X[p2_train[i][1]]\n",
    "    X2_train[i,TOP_N_GENES*2:diverg_tr.shape[1]+TOP_N_GENES*2] = diverg_tr[p2_train[i][0]][0]\n",
    "    X2_train[i,TOP_N_GENES*2+diverg_tr.shape[1]:] = diverg_tr[p2_train[i][1]][0]\n",
    "    Y2_train[i,:] = X[p2_train[i][2]]\n",
    "    \n",
    "\n",
    "X2_test = np.zeros(shape=(len(p2_test),TOP_N_GENES*2+diverg_ts.shape[1]))\n",
    "Y2_test = np.zeros(shape=(len(p2_test),TOP_N_GENES))\n",
    "\n",
    "for i in tqdm(range(Y2_test.shape[0])):\n",
    "    X2_test[i,:TOP_N_GENES] = X[p2_dataset[i][0]]\n",
    "    X2_test[i,TOP_N_GENES:TOP_N_GENES*2] = X[p2_dataset[i][1]]\n",
    "    X2_test[i,TOP_N_GENES*2:diverg_ts.shape[1]+TOP_N_GENES*2] = diverg_ts[p2_test[i][0]][0]\n",
    "    X2_test[i,TOP_N_GENES*2+diverg_ts.shape[1]:] = diverg_ts[p2_test[i][1]][0]\n",
    "    \n",
    "    Y2_test[i,:] = X[p2_dataset[i][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c96ec510-1935-41e5-9b64-2054f2200a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6795, 300), (2920, 300))"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_test.shape, X2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "ae9bdd0b-7c89-47e7-9e63-e9223b10cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_val, Y2_train, Y2_val = train_test_split(X2_train, Y2_train, \n",
    "                                                  test_size=0.3, \n",
    "                                                  random_state=42,\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "65b9b0ec-3786-4f98-b311-28f8f3e245a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 39.5022582\ttest: 41.7953592\tbest: 41.7953592 (0)\ttotal: 10.2s\tremaining: 25m 12s\n",
      "1:\tlearn: 38.2300950\ttest: 41.8848557\tbest: 41.7953592 (0)\ttotal: 19.9s\tremaining: 24m 31s\n",
      "2:\tlearn: 37.5985850\ttest: 41.9403278\tbest: 41.7953592 (0)\ttotal: 29.2s\tremaining: 23m 49s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[263], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m CatBoostRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#model = LGBMRegressor(objective='regression_l2', metric='l2', num_iterations=50, verbose=-1)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX2_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY2_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX2_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY2_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                              \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[1;32m     22\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X2_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catboost/core.py:5827\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5825\u001b[0m     CatBoostRegressor\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5827\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5828\u001b[0m \u001b[43m                 \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5829\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5830\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catboost/core.py:2400\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2397\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2399\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2400\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2406\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2408\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2409\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/catboost/core.py:1780\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4833\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4882\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {'learning_rate': 0.3, \n",
    "          'depth': 12, \n",
    "          'l2_leaf_reg': 3, \n",
    "          'loss_function': 'MultiRMSE', \n",
    "          'eval_metric': 'MultiRMSE', \n",
    "          'task_type': 'CPU', \n",
    "          'iterations': 150,\n",
    "          'od_type': 'Iter', \n",
    "          'boosting_type': 'Plain', \n",
    "          'bootstrap_type': 'Bernoulli', \n",
    "          'allow_const_label': True, \n",
    "         }\n",
    "\n",
    "model = CatBoostRegressor(**params)\n",
    "#model = LGBMRegressor(objective='regression_l2', metric='l2', num_iterations=50, verbose=-1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X2_train, Y2_train, eval_set=[(X2_val, Y2_val)], early_stopping_rounds = 50, \n",
    "                              use_best_model = True, verbose = 1)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7ca81653-f8f6-4c16-9aaf-ff9bf59775ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013978</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.125816</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.844329</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.118969</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.001614</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.199218</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.114377</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.658550</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.001018</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.279788</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.142634</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.001363</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.906188</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.129038</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.653317</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.131884</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.000969</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.000917</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.008807</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16.000490</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>15.120231</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1\n",
       "0    0.013978   0.0\n",
       "1    0.000000   0.0\n",
       "2    0.125816   0.0\n",
       "3    0.844329   0.0\n",
       "4    0.118969   0.0\n",
       "5   -0.001614   0.0\n",
       "6    0.000161   0.0\n",
       "7    1.199218   1.0\n",
       "8    0.114377   0.0\n",
       "9    1.658550   0.0\n",
       "10  -0.001018   0.0\n",
       "11   0.279788   0.0\n",
       "12   0.142634   0.0\n",
       "13  -0.001363   0.0\n",
       "14   1.906188   1.0\n",
       "15   0.129038   0.0\n",
       "16   0.653317   1.0\n",
       "17   0.000000   0.0\n",
       "18   1.131884   1.0\n",
       "19  -0.000969   0.0\n",
       "20   0.000000   0.0\n",
       "21  -0.000917   0.0\n",
       "22   0.000000   0.0\n",
       "23  -0.008807   0.0\n",
       "24  16.000490  16.0\n",
       "25  15.120231  16.0\n",
       "26   0.000000   0.0\n",
       "27   0.000000   0.0\n",
       "28   0.000109   0.0\n",
       "29   0.000000   0.0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([y_pred[0],Y2_test[0]]).T.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f6b2efe4-9dee-4280-bdcd-4a31269cb2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0., 16., 16.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  9.,  0.,  0.,  0., 22.,  0.,  0.,\n",
       "        1.,  1., 11.,  0.,  0.,  0.,  0.,  0.,  0., 15.,  0.,  0., 13.,\n",
       "        0., 13.,  0.,  0.,  0.,  0.,  0., 11.,  0.,  0., 20.,  6.,  0.,\n",
       "        1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  0., 12., 30.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,\n",
       "        0.,  0.,  9.,  0.,  1.,  9.,  1.,  6.,  0.])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdb9946-1f08-42c6-9cd8-dca7852247a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
