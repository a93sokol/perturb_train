{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2357a85-4d3f-4793-9b5b-a356c9cf75c0",
   "metadata": {},
   "source": [
    "## Nonlinear DEGs from PerturbSeq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef338e8d-6c1a-4e0f-95bd-489a295a13da",
   "metadata": {},
   "source": [
    "#### Background\n",
    "- We have got a reactome similarity matrix between the perturbed genes, both in desiase and healthly.\n",
    "- We know that DEGs-based similarity matrix has a statistically significant overlap with the reactome similarty matrix. \n",
    "- We want to extract knowledge from the perturbSeq dataset which would overlap with the reactome pathways.\n",
    "- We already tried to build a VAE-based model learning a tree representation of every perturbation. Even though it gives promising results, it requires further tuning/refinement as the stability of the solution is low. Specifically, adjustment of the loss function and the learning concept might be needed. \n",
    "\n",
    "#### The Why?\n",
    "- Why do we believe it is reasonable to do? DEGs are computed using t-test and have a statistically significant overlap with reactome. If we incorporate nonlinearity into DEGs in some way, we might get an even stronger result.\n",
    "- Why do we want to do it? It would give us a subset of perspective relationships between genes whose exploration would potentially lead to new biological findings.\n",
    "\n",
    "#### The How? \n",
    "- What is the simplest way? Take a binary boosting trees classifier (lgbm or catboost), and find the top useful features for every perturbation, for the model classifying into ctrl vs perturbed state.\n",
    "- What is the more advanced approach? Having a similarity matrix, we can refine it by building binary classfiers for perturbation A vs perturbation B task. This would allow to exclude/highlight differences between the perturbations. The classifier performance and its feature importances would be used for the refinement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf26e58-960e-40d1-b160-be4876747e6f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "be7da009-644e-4c15-a074-ab1671daf24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as scp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import catboost as cb\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from collections import Counter\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28545cb6-f504-4523-8ea6-0e37ec165a9f",
   "metadata": {},
   "source": [
    "### Magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2d1aad38-4497-4f8c-b5ed-c17b65b5fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENE_PER_CELL_BINNING = True\n",
    "N_BINS = 1000\n",
    "N_ITER = 50\n",
    "TOP_N_GENES = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c34cd4-4903-47d4-aeba-57aa5aff6e2b",
   "metadata": {},
   "source": [
    "### Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "579f1ded-ce0a-442a-9f46-aac212209692",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = scp.read_h5ad('./data/Norman_2019/norman_umi_go/perturb_processed.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dc17e045-10e5-4a5f-853c-c02d17410346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "## Following the scGPT paper, we bin the genes within cell. \n",
    "\n",
    "def bin_nonzero_values(arr, num_bins):\n",
    "    # Filter out non-zero values\n",
    "    nonzero_vals = arr[arr != 0]\n",
    "    \n",
    "    # Calculate bin edges\n",
    "    bin_edges = np.linspace(nonzero_vals.min(), nonzero_vals.max(), num_bins)\n",
    "    \n",
    "    # Bin the values\n",
    "    binned_values = np.zeros_like(arr)\n",
    "    binned_nonzero = np.digitize(nonzero_vals, bin_edges)\n",
    "    binned_values[arr != 0] = binned_nonzero\n",
    "    \n",
    "    return binned_values\n",
    "\n",
    "# Example usage\n",
    "arr = np.random.randint(low=0, high=100, size=100)\n",
    "num_bins = 3\n",
    "binned_values = bin_nonzero_values(arr, num_bins)\n",
    "print(set(binned_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6ff55295-12fe-41f9-b7f6-b122df4533cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scp.pp.normalize_total(adata, exclude_highly_expressed=True)\n",
    "scp.pp.log1p(adata)\n",
    "scp.pp.highly_variable_genes(adata, n_top_genes=TOP_N_GENES,subset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e7de02c3-4aa2-40cd-81e5-7d07ce966e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 91205/91205 [00:18<00:00, 4826.69it/s]\n"
     ]
    }
   ],
   "source": [
    "if GENE_PER_CELL_BINNING:\n",
    "    tempy = adata.X.toarray()\n",
    "    \n",
    "    for c in tqdm(range(adata.X.shape[0])):\n",
    "        tempy[c,:] = bin_nonzero_values(tempy[c,:], N_BINS)\n",
    "    \n",
    "    adata.X = sparse.csr_matrix(tempy)\n",
    "    del tempy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "52090a5e-fa6d-4b5f-b6cb-f5a165b2e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = adata.obs.condition.values.astype(str)\n",
    "X = adata.X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3860c67f-8e68-4392-9d93-b32474c79f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducer = umap.UMAP(n_neighbors=10,verbose=True)\n",
    "# embedding = reducer.fit_transform(X)\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# encoder = LabelEncoder()\n",
    "# colors = encoder.fit_transform(y)\n",
    "\n",
    "# plt.scatter(embedding[:,0],embedding[:,1], c=colors, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f89477f-1df6-4a8d-9a2d-bc4fddbc302d",
   "metadata": {},
   "source": [
    "### Build divergence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4d56bed8-ed04-4026-9a23-d5edb73f5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_folds(X, y, n_splits=10):\n",
    "#     skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "#     return list(skf.split(X, y))\n",
    "\n",
    "# def train_and_evaluate(X_train, y_train, X_test, n_stages=5, iterations=100):\n",
    "#     model = CatBoostClassifier(iterations=iterations, depth=6, learning_rate=0.1, verbose=0)\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     staged_predictions = []\n",
    "#     stage_interval = iterations // n_stages\n",
    "#     for i in range(stage_interval, iterations + 1, stage_interval):\n",
    "#         staged_predictions.append(model.predict(X_test, ntree_end=i))\n",
    "    \n",
    "#     return staged_predictions\n",
    "\n",
    "# def main(X, y, k_folds=10, k_repeats=3, n_stages=5, iterations=100):\n",
    "#     perturbations = list(set(y))\n",
    "#     perturbation_index = {p: i for i, p in enumerate(perturbations)}\n",
    "#     results_matrix = np.zeros((len(y), len(perturbations)))\n",
    "#     evaluation_count = np.zeros(len(y))\n",
    "\n",
    "#     fold_idx = 0\n",
    "#     total_iterations = k_repeats * n_stages\n",
    "#     with tqdm(total=total_iterations, desc=\"Evaluations\") as pbar:\n",
    "#         while np.any(evaluation_count < k_repeats * n_stages):\n",
    "#             skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=fold_idx)\n",
    "#             for train_idx, test_idx in tqdm(skf.split(X, y), total=k_folds, desc=f\"Fold {fold_idx+1}\"):\n",
    "#                 X_train, y_train = X[train_idx], y[train_idx]\n",
    "#                 X_test, y_test = X[test_idx], y[test_idx]\n",
    "#                 staged_predictions = train_and_evaluate(X_train, y_train, X_test, n_stages, iterations)\n",
    "                \n",
    "#                 for stage_predictions in staged_predictions:\n",
    "#                     for idx, (true_label, pred_label) in enumerate(zip(y_test, stage_predictions)):\n",
    "#                         cell_idx = test_idx[idx]\n",
    "#                         pred_label = pred_label.item()  # Convert numpy scalar to a Python scalar\n",
    "#                         pred_label_index = perturbation_index[pred_label]\n",
    "#                         if evaluation_count[cell_idx] < k_repeats * n_stages:\n",
    "#                             results_matrix[cell_idx, pred_label_index] += 1\n",
    "#                             evaluation_count[cell_idx] += 1\n",
    "#                     pbar.update(1)\n",
    "\n",
    "#                     if np.all(evaluation_count >= k_repeats * n_stages):\n",
    "#                         break\n",
    "            \n",
    "#             fold_idx += 1\n",
    "\n",
    "#     return results_matrix, perturbations\n",
    "\n",
    "# # Example usage with dummy data\n",
    "# # X = np.random.rand(100, 10)  # 100 cells, 10 genes\n",
    "# # y = np.random.choice(['ctrl+A', 'A+ctrl', 'A+B', 'C+D'], size=100)  # Perturbations\n",
    "\n",
    "# results_matrix, perturbations = main(X, y, k_folds=3, k_repeats=2, n_stages=10, iterations=50)\n",
    "# #print(results_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "df667cf6-6a14-4391-a48b-7c1ccbe95846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('perturb_mtx', results_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "421c3da9-72a2-454f-a015-deb177193843",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_matrix = np.load('perturb_mtx.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c2df5644-735d-4413-b5f7-47186493d05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.99)\n",
    "results_matrix_red = pca.fit_transform(results_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7cfcb-b34d-4a7f-8c5a-9dfbe3e07b1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc_mu: 0.764364\tvalid_0's multi_logloss: 6.58296\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc_mu: 0.783759\tvalid_0's multi_logloss: 11.9564\n",
      "[3]\tvalid_0's auc_mu: 0.805868\tvalid_0's multi_logloss: 19.4454\n",
      "[4]\tvalid_0's auc_mu: 0.77779\tvalid_0's multi_logloss: 24.4433\n",
      "[5]\tvalid_0's auc_mu: 0.7474\tvalid_0's multi_logloss: 27.4841\n",
      "[6]\tvalid_0's auc_mu: 0.700679\tvalid_0's multi_logloss: 29.4669\n",
      "[7]\tvalid_0's auc_mu: 0.664203\tvalid_0's multi_logloss: 31.1339\n",
      "[8]\tvalid_0's auc_mu: 0.666464\tvalid_0's multi_logloss: 31.7017\n",
      "[9]\tvalid_0's auc_mu: 0.659204\tvalid_0's multi_logloss: 31.8221\n",
      "[10]\tvalid_0's auc_mu: 0.645206\tvalid_0's multi_logloss: 32.245\n",
      "[11]\tvalid_0's auc_mu: 0.643966\tvalid_0's multi_logloss: 34.0051\n",
      "[12]\tvalid_0's auc_mu: 0.642455\tvalid_0's multi_logloss: 33.519\n",
      "[13]\tvalid_0's auc_mu: 0.638053\tvalid_0's multi_logloss: 33.6747\n",
      "[14]\tvalid_0's auc_mu: 0.636237\tvalid_0's multi_logloss: 34.0078\n",
      "[15]\tvalid_0's auc_mu: 0.634625\tvalid_0's multi_logloss: 33.7537\n",
      "[16]\tvalid_0's auc_mu: 0.631151\tvalid_0's multi_logloss: 33.7381\n",
      "[17]\tvalid_0's auc_mu: 0.627269\tvalid_0's multi_logloss: 33.987\n",
      "[18]\tvalid_0's auc_mu: 0.626819\tvalid_0's multi_logloss: 33.4589\n",
      "[19]\tvalid_0's auc_mu: 0.622674\tvalid_0's multi_logloss: 33.5063\n",
      "[20]\tvalid_0's auc_mu: 0.621103\tvalid_0's multi_logloss: 33.3753\n",
      "[21]\tvalid_0's auc_mu: 0.618912\tvalid_0's multi_logloss: 33.7452\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                  test_size=0.3, \n",
    "                                                  random_state=42,\n",
    "                                                  )\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=42,\n",
    "                                                  )\n",
    "\n",
    "model = LGBMClassifier(verbose=-1, n_jobs=10)\n",
    "model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='auc_mu',    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=100),\n",
    "        lgb.log_evaluation(1)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1670e9b1-1ebe-4891-97da-b5a766352a22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# similarity_res = np.zeros(shape=(X.shape[0], N_ITER),dtype=object) \n",
    "# for i in tqdm(range(N_ITER)):\n",
    "#     y_pred = model.predict_proba(X_test,num_iteration=250)\n",
    "#     break\n",
    "\n",
    "# #similarity_res[curr_idx_test, i] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51280c3f-0b44-42e5-a6df-6be8e32dbd10",
   "metadata": {},
   "source": [
    "## Preparing data from the second part - first, naive without the divergences, then adding it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c83cb040-3a31-4625-b26a-02dcb39a116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([i.translate(str.maketrans('', '', '+ctrl')) if ('+' in i and 'ctrl' in i) else i for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "50b3f8ee-7f5b-4948-8876-3c841c0185fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 27969/27969 [00:17<00:00, 1612.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 7476/7476 [00:04<00:00, 1609.65it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_classes = np.unique(y)\n",
    "classes_train, classes_test = train_test_split(unique_classes, test_size=0.2, random_state=47)\n",
    "\n",
    "# Filter the data based on the selected classes for training and testing\n",
    "curr_idx_mask = np.isin(y, classes_train)\n",
    "X_train, y_train = X[curr_idx_mask], y[curr_idx_mask]\n",
    "X_test, y_test = X[~curr_idx_mask], y[~curr_idx_mask]\n",
    "\n",
    "diverg_tr = results_matrix_red[curr_idx_mask]\n",
    "diverg_ts = results_matrix_red[~curr_idx_mask]\n",
    "\n",
    "double_pert_ids_tr = []\n",
    "for s in range(y_train.shape[0]):\n",
    "    if '+' in y_train[s] and 'ctrl' not in y_train[s]:\n",
    "        double_pert_ids_tr.append(s)\n",
    "\n",
    "double_pert_ids_ts = []\n",
    "for s in range(y_test.shape[0]):\n",
    "    if '+' in y_test[s] and 'ctrl' not in y_test[s]:\n",
    "        double_pert_ids_ts.append(s)\n",
    "\n",
    "\n",
    "# First for training\n",
    "dic = {}\n",
    "\n",
    "p2_train = []\n",
    "for dp_id in tqdm(double_pert_ids_tr):\n",
    "    c1, c2 = y_train[dp_id].split('+')\n",
    "    if c1 in y and c2 in y:       \n",
    "        if c1 not in dic.keys():\n",
    "            dic[c1] = np.where(np.array(y)==c1)[0]\n",
    "        if c2 not in dic.keys():\n",
    "            dic[c2] = np.where(np.array(y)==c2)[0]\n",
    "        \n",
    "        pos1 = np.random.choice(dic[c1])\n",
    "        pos2 = np.random.choice(dic[c2])\n",
    "        \n",
    "        p2_train.append((pos1, pos2, dp_id))\n",
    "\n",
    "# Then for testing\n",
    "p2_test = []\n",
    "dic = {}\n",
    "for dp_id in tqdm(double_pert_ids_ts):\n",
    "    c1, c2 = y_test[dp_id].split('+')\n",
    "    \n",
    "    if c1 in y and c2 in y:   \n",
    "        if c1 not in dic.keys():\n",
    "            dic[c1] = np.where(np.array(y)==c1)[0]        \n",
    "        if c2 not in dic.keys():\n",
    "            dic[c2] = np.where(np.array(y)==c2)[0]\n",
    "        \n",
    "        pos1 = np.random.choice(dic[c1])\n",
    "        pos2 = np.random.choice(dic[c2])\n",
    "        \n",
    "        p2_test.append((pos1, pos2, dp_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "07f95921-753a-45ba-9149-248164c657c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 27695/27695 [00:01<00:00, 19508.66it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 7427/7427 [00:00<00:00, 19592.56it/s]\n"
     ]
    }
   ],
   "source": [
    "X2_train = np.zeros(shape=(len(p2_train),TOP_N_GENES*2+diverg_tr.shape[1]*2))\n",
    "Y2_train = np.zeros(shape=(len(p2_train),TOP_N_GENES))\n",
    "\n",
    "for i in tqdm(range(Y2_train.shape[0])):\n",
    "    X2_train[i,:TOP_N_GENES] = X[p2_train[i][0]]\n",
    "    X2_train[i,TOP_N_GENES:TOP_N_GENES*2] = X[p2_train[i][1]]\n",
    "    X2_train[i,TOP_N_GENES*2:diverg_tr.shape[1]+TOP_N_GENES*2] = results_matrix_red[p2_train[i][0]][0]\n",
    "    X2_train[i,TOP_N_GENES*2+diverg_tr.shape[1]:] = results_matrix_red[p2_train[i][1]][0]\n",
    "    Y2_train[i,:] = X_train[p2_train[i][2]]\n",
    "    \n",
    "\n",
    "X2_test = np.zeros(shape=(len(p2_test),TOP_N_GENES*2+diverg_ts.shape[1]*2))\n",
    "Y2_test = np.zeros(shape=(len(p2_test),TOP_N_GENES))\n",
    "\n",
    "for i in tqdm(range(Y2_test.shape[0])):\n",
    "    X2_test[i,:TOP_N_GENES] = X[p2_test[i][0]]\n",
    "    X2_test[i,TOP_N_GENES:TOP_N_GENES*2] = X[p2_test[i][1]]\n",
    "    X2_test[i,TOP_N_GENES*2:diverg_ts.shape[1]+TOP_N_GENES*2] = results_matrix_red[p2_test[i][0]][0]\n",
    "    X2_test[i,TOP_N_GENES*2+diverg_ts.shape[1]:] = results_matrix_red[p2_test[i][1]][0]\n",
    "    \n",
    "    Y2_test[i,:] = X_test[p2_test[i][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c96ec510-1935-41e5-9b64-2054f2200a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7427, 10144), (27695, 10144))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_test.shape, X2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ae9bdd0b-7c89-47e7-9e63-e9223b10cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_val, Y2_train, Y2_val = train_test_split(X2_train, Y2_train, \n",
    "                                                  test_size=0.3, \n",
    "                                                  random_state=42,\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "65b9b0ec-3786-4f98-b311-28f8f3e245a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 179.3670647\ttest: 179.1546135\tbest: 179.1546135 (0)\ttotal: 2.1s\tremaining: 8m 43s\n",
      "1:\tlearn: 179.2232065\ttest: 179.0672082\tbest: 179.0672082 (1)\ttotal: 4.56s\tremaining: 9m 25s\n",
      "2:\tlearn: 179.1472540\ttest: 179.0564144\tbest: 179.0564144 (2)\ttotal: 6.93s\tremaining: 9m 30s\n",
      "3:\tlearn: 178.9816866\ttest: 178.9312948\tbest: 178.9312948 (3)\ttotal: 9.38s\tremaining: 9m 36s\n",
      "4:\tlearn: 178.8745401\ttest: 178.8661152\tbest: 178.8661152 (4)\ttotal: 12.4s\tremaining: 10m 8s\n",
      "5:\tlearn: 178.7850966\ttest: 178.8338373\tbest: 178.8338373 (5)\ttotal: 15s\tremaining: 10m 11s\n",
      "6:\tlearn: 178.7260883\ttest: 178.8126205\tbest: 178.8126205 (6)\ttotal: 17.6s\tremaining: 10m 10s\n",
      "7:\tlearn: 178.6319899\ttest: 178.7610195\tbest: 178.7610195 (7)\ttotal: 20s\tremaining: 10m 5s\n",
      "8:\tlearn: 178.5776093\ttest: 178.7404781\tbest: 178.7404781 (8)\ttotal: 22.2s\tremaining: 9m 54s\n",
      "9:\tlearn: 178.5159343\ttest: 178.7297751\tbest: 178.7297751 (9)\ttotal: 24.6s\tremaining: 9m 50s\n",
      "10:\tlearn: 178.4580169\ttest: 178.7233486\tbest: 178.7233486 (10)\ttotal: 26.9s\tremaining: 9m 45s\n",
      "11:\tlearn: 178.4021016\ttest: 178.7248670\tbest: 178.7233486 (10)\ttotal: 29.3s\tremaining: 9m 40s\n",
      "12:\tlearn: 178.3247950\ttest: 178.6958611\tbest: 178.6958611 (12)\ttotal: 31.6s\tremaining: 9m 35s\n",
      "13:\tlearn: 178.2904379\ttest: 178.6846824\tbest: 178.6846824 (13)\ttotal: 33.7s\tremaining: 9m 27s\n",
      "14:\tlearn: 178.2097947\ttest: 178.6539946\tbest: 178.6539946 (14)\ttotal: 36.2s\tremaining: 9m 27s\n",
      "15:\tlearn: 178.1591784\ttest: 178.6571113\tbest: 178.6539946 (14)\ttotal: 38.7s\tremaining: 9m 26s\n",
      "16:\tlearn: 178.0909793\ttest: 178.6653029\tbest: 178.6539946 (14)\ttotal: 41.3s\tremaining: 9m 25s\n",
      "17:\tlearn: 178.0431483\ttest: 178.6613080\tbest: 178.6539946 (14)\ttotal: 43.9s\tremaining: 9m 25s\n",
      "18:\tlearn: 177.9658532\ttest: 178.6371576\tbest: 178.6371576 (18)\ttotal: 46.1s\tremaining: 9m 20s\n",
      "19:\tlearn: 177.9228757\ttest: 178.6367463\tbest: 178.6367463 (19)\ttotal: 48.2s\tremaining: 9m 14s\n",
      "20:\tlearn: 177.8497386\ttest: 178.6142600\tbest: 178.6142600 (20)\ttotal: 50.3s\tremaining: 9m 8s\n",
      "21:\tlearn: 177.7917298\ttest: 178.5966869\tbest: 178.5966869 (21)\ttotal: 52.4s\tremaining: 9m 3s\n",
      "22:\tlearn: 177.7448889\ttest: 178.5893581\tbest: 178.5893581 (22)\ttotal: 54.5s\tremaining: 8m 58s\n",
      "23:\tlearn: 177.6952257\ttest: 178.5786833\tbest: 178.5786833 (23)\ttotal: 56.4s\tremaining: 8m 50s\n",
      "24:\tlearn: 177.6377928\ttest: 178.5800459\tbest: 178.5786833 (23)\ttotal: 58.5s\tremaining: 8m 46s\n",
      "25:\tlearn: 177.5914443\ttest: 178.5969443\tbest: 178.5786833 (23)\ttotal: 1m\tremaining: 8m 42s\n",
      "26:\tlearn: 177.4906359\ttest: 178.5400689\tbest: 178.5400689 (26)\ttotal: 1m 3s\tremaining: 8m 41s\n",
      "27:\tlearn: 177.4252212\ttest: 178.5561684\tbest: 178.5400689 (26)\ttotal: 1m 5s\tremaining: 8m 37s\n",
      "28:\tlearn: 177.3966784\ttest: 178.5621091\tbest: 178.5400689 (26)\ttotal: 1m 7s\tremaining: 8m 31s\n",
      "29:\tlearn: 177.3364768\ttest: 178.5566789\tbest: 178.5400689 (26)\ttotal: 1m 8s\tremaining: 8m 25s\n",
      "30:\tlearn: 177.3083949\ttest: 178.5517032\tbest: 178.5400689 (26)\ttotal: 1m 10s\tremaining: 8m 20s\n",
      "31:\tlearn: 177.2317352\ttest: 178.5443847\tbest: 178.5400689 (26)\ttotal: 1m 12s\tremaining: 8m 14s\n",
      "32:\tlearn: 177.1792803\ttest: 178.5517916\tbest: 178.5400689 (26)\ttotal: 1m 14s\tremaining: 8m 11s\n",
      "33:\tlearn: 177.1235675\ttest: 178.5365554\tbest: 178.5365554 (33)\ttotal: 1m 16s\tremaining: 8m 7s\n",
      "34:\tlearn: 177.0659579\ttest: 178.5316909\tbest: 178.5316909 (34)\ttotal: 1m 19s\tremaining: 8m 5s\n",
      "35:\tlearn: 176.9927316\ttest: 178.5159837\tbest: 178.5159837 (35)\ttotal: 1m 21s\tremaining: 8m 3s\n",
      "36:\tlearn: 176.9045767\ttest: 178.5146106\tbest: 178.5146106 (36)\ttotal: 1m 23s\tremaining: 8m 1s\n",
      "37:\tlearn: 176.8667177\ttest: 178.5233588\tbest: 178.5146106 (36)\ttotal: 1m 25s\tremaining: 7m 59s\n",
      "38:\tlearn: 176.7877146\ttest: 178.5064186\tbest: 178.5064186 (38)\ttotal: 1m 28s\tremaining: 7m 57s\n",
      "39:\tlearn: 176.6897679\ttest: 178.4965065\tbest: 178.4965065 (39)\ttotal: 1m 30s\tremaining: 7m 55s\n",
      "40:\tlearn: 176.5996666\ttest: 178.4528424\tbest: 178.4528424 (40)\ttotal: 1m 33s\tremaining: 7m 54s\n",
      "41:\tlearn: 176.5119065\ttest: 178.4322403\tbest: 178.4322403 (41)\ttotal: 1m 35s\tremaining: 7m 52s\n",
      "42:\tlearn: 176.4160269\ttest: 178.4297828\tbest: 178.4297828 (42)\ttotal: 1m 37s\tremaining: 7m 49s\n",
      "43:\tlearn: 176.3124063\ttest: 178.4381953\tbest: 178.4297828 (42)\ttotal: 1m 39s\tremaining: 7m 47s\n",
      "44:\tlearn: 176.2283701\ttest: 178.4415540\tbest: 178.4297828 (42)\ttotal: 1m 41s\tremaining: 7m 44s\n",
      "45:\tlearn: 176.1830471\ttest: 178.4560940\tbest: 178.4297828 (42)\ttotal: 1m 43s\tremaining: 7m 40s\n",
      "46:\tlearn: 176.1236883\ttest: 178.4615006\tbest: 178.4297828 (42)\ttotal: 1m 45s\tremaining: 7m 37s\n",
      "47:\tlearn: 176.0410343\ttest: 178.4577313\tbest: 178.4297828 (42)\ttotal: 1m 48s\tremaining: 7m 35s\n",
      "48:\tlearn: 176.0148538\ttest: 178.4646582\tbest: 178.4297828 (42)\ttotal: 1m 50s\tremaining: 7m 31s\n",
      "49:\tlearn: 175.9297002\ttest: 178.4724225\tbest: 178.4297828 (42)\ttotal: 1m 52s\tremaining: 7m 28s\n",
      "50:\tlearn: 175.8356812\ttest: 178.5112413\tbest: 178.4297828 (42)\ttotal: 1m 54s\tremaining: 7m 26s\n",
      "51:\tlearn: 175.7647838\ttest: 178.4949456\tbest: 178.4297828 (42)\ttotal: 1m 56s\tremaining: 7m 23s\n",
      "52:\tlearn: 175.7322630\ttest: 178.4827373\tbest: 178.4297828 (42)\ttotal: 1m 58s\tremaining: 7m 20s\n",
      "53:\tlearn: 175.7032130\ttest: 178.4869062\tbest: 178.4297828 (42)\ttotal: 2m\tremaining: 7m 16s\n",
      "54:\tlearn: 175.6116684\ttest: 178.4983022\tbest: 178.4297828 (42)\ttotal: 2m 2s\tremaining: 7m 13s\n",
      "55:\tlearn: 175.5444050\ttest: 178.5015259\tbest: 178.4297828 (42)\ttotal: 2m 4s\tremaining: 7m 10s\n",
      "56:\tlearn: 175.4525520\ttest: 178.5136647\tbest: 178.4297828 (42)\ttotal: 2m 6s\tremaining: 7m 8s\n",
      "57:\tlearn: 175.3624715\ttest: 178.5262642\tbest: 178.4297828 (42)\ttotal: 2m 8s\tremaining: 7m 4s\n",
      "58:\tlearn: 175.3241785\ttest: 178.5348475\tbest: 178.4297828 (42)\ttotal: 2m 10s\tremaining: 7m 1s\n",
      "59:\tlearn: 175.2573529\ttest: 178.5252672\tbest: 178.4297828 (42)\ttotal: 2m 12s\tremaining: 6m 58s\n",
      "60:\tlearn: 175.1625453\ttest: 178.5311682\tbest: 178.4297828 (42)\ttotal: 2m 14s\tremaining: 6m 55s\n",
      "61:\tlearn: 175.0737589\ttest: 178.5365357\tbest: 178.4297828 (42)\ttotal: 2m 15s\tremaining: 6m 52s\n",
      "62:\tlearn: 174.9956355\ttest: 178.5457015\tbest: 178.4297828 (42)\ttotal: 2m 17s\tremaining: 6m 49s\n",
      "63:\tlearn: 174.9769795\ttest: 178.5554673\tbest: 178.4297828 (42)\ttotal: 2m 19s\tremaining: 6m 45s\n",
      "64:\tlearn: 174.9085056\ttest: 178.5752345\tbest: 178.4297828 (42)\ttotal: 2m 21s\tremaining: 6m 43s\n",
      "65:\tlearn: 174.8133579\ttest: 178.5764492\tbest: 178.4297828 (42)\ttotal: 2m 23s\tremaining: 6m 41s\n",
      "66:\tlearn: 174.7972753\ttest: 178.5742000\tbest: 178.4297828 (42)\ttotal: 2m 25s\tremaining: 6m 37s\n",
      "67:\tlearn: 174.7330821\ttest: 178.5602449\tbest: 178.4297828 (42)\ttotal: 2m 27s\tremaining: 6m 34s\n",
      "68:\tlearn: 174.6417101\ttest: 178.5742316\tbest: 178.4297828 (42)\ttotal: 2m 29s\tremaining: 6m 32s\n",
      "69:\tlearn: 174.6286583\ttest: 178.5742522\tbest: 178.4297828 (42)\ttotal: 2m 31s\tremaining: 6m 29s\n",
      "70:\tlearn: 174.5746131\ttest: 178.5786782\tbest: 178.4297828 (42)\ttotal: 2m 33s\tremaining: 6m 28s\n",
      "71:\tlearn: 174.4842148\ttest: 178.5740417\tbest: 178.4297828 (42)\ttotal: 2m 36s\tremaining: 6m 27s\n",
      "72:\tlearn: 174.4704011\ttest: 178.5744001\tbest: 178.4297828 (42)\ttotal: 2m 38s\tremaining: 6m 24s\n",
      "73:\tlearn: 174.3893594\ttest: 178.5995221\tbest: 178.4297828 (42)\ttotal: 2m 41s\tremaining: 6m 23s\n",
      "74:\tlearn: 174.3062662\ttest: 178.6130763\tbest: 178.4297828 (42)\ttotal: 2m 43s\tremaining: 6m 22s\n",
      "75:\tlearn: 174.2282786\ttest: 178.6324584\tbest: 178.4297828 (42)\ttotal: 2m 46s\tremaining: 6m 21s\n",
      "76:\tlearn: 174.1647512\ttest: 178.6499594\tbest: 178.4297828 (42)\ttotal: 2m 48s\tremaining: 6m 18s\n",
      "77:\tlearn: 174.1108900\ttest: 178.6419076\tbest: 178.4297828 (42)\ttotal: 2m 50s\tremaining: 6m 15s\n",
      "78:\tlearn: 174.0325601\ttest: 178.6219371\tbest: 178.4297828 (42)\ttotal: 2m 52s\tremaining: 6m 13s\n",
      "79:\tlearn: 173.9762555\ttest: 178.6305947\tbest: 178.4297828 (42)\ttotal: 2m 54s\tremaining: 6m 10s\n",
      "80:\tlearn: 173.9177555\ttest: 178.6308595\tbest: 178.4297828 (42)\ttotal: 2m 56s\tremaining: 6m 8s\n",
      "81:\tlearn: 173.8163871\ttest: 178.6502171\tbest: 178.4297828 (42)\ttotal: 2m 58s\tremaining: 6m 6s\n",
      "82:\tlearn: 173.7104244\ttest: 178.6774353\tbest: 178.4297828 (42)\ttotal: 3m\tremaining: 6m 4s\n",
      "83:\tlearn: 173.6460722\ttest: 178.6619948\tbest: 178.4297828 (42)\ttotal: 3m 3s\tremaining: 6m 1s\n",
      "84:\tlearn: 173.5883042\ttest: 178.6776797\tbest: 178.4297828 (42)\ttotal: 3m 5s\tremaining: 5m 59s\n",
      "85:\tlearn: 173.5178832\ttest: 178.6878001\tbest: 178.4297828 (42)\ttotal: 3m 7s\tremaining: 5m 57s\n",
      "86:\tlearn: 173.4969068\ttest: 178.6853960\tbest: 178.4297828 (42)\ttotal: 3m 9s\tremaining: 5m 54s\n",
      "87:\tlearn: 173.4253498\ttest: 178.6946891\tbest: 178.4297828 (42)\ttotal: 3m 11s\tremaining: 5m 52s\n",
      "88:\tlearn: 173.3496684\ttest: 178.7063794\tbest: 178.4297828 (42)\ttotal: 3m 13s\tremaining: 5m 50s\n",
      "89:\tlearn: 173.2652623\ttest: 178.7136042\tbest: 178.4297828 (42)\ttotal: 3m 15s\tremaining: 5m 48s\n",
      "90:\tlearn: 173.2006388\ttest: 178.7202298\tbest: 178.4297828 (42)\ttotal: 3m 17s\tremaining: 5m 45s\n",
      "91:\tlearn: 173.1419541\ttest: 178.7069068\tbest: 178.4297828 (42)\ttotal: 3m 19s\tremaining: 5m 43s\n",
      "92:\tlearn: 173.0474475\ttest: 178.7101588\tbest: 178.4297828 (42)\ttotal: 3m 22s\tremaining: 5m 41s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 178.4297828\n",
      "bestIteration = 42\n",
      "\n",
      "Shrink model to first 43 iterations.\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate': 0.3, \n",
    "          'depth': 4, \n",
    "          'l2_leaf_reg': 3, \n",
    "          'loss_function': 'MultiRMSE', \n",
    "          'eval_metric': 'MultiRMSE', \n",
    "          'task_type': 'CPU', \n",
    "          'iterations': 250,\n",
    "          'od_type': 'Iter', \n",
    "          'boosting_type': 'Plain', \n",
    "          'bootstrap_type': 'Bernoulli', \n",
    "          'allow_const_label': True, \n",
    "         }\n",
    "\n",
    "model = CatBoostRegressor(**params)\n",
    "#model = LGBMRegressor(objective='regression_l2', metric='l2', num_iterations=50, verbose=-1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X2_train[:,:], Y2_train[:,:10], eval_set=[(X2_val[:,:], Y2_val[:,:10])], early_stopping_rounds = 50, \n",
    "                              use_best_model = True, verbose = 1)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82feb582-8aa3-41c7-a606-1a8e910232ff",
   "metadata": {},
   "source": [
    "### Let's explore data and see whether classes can be distinguished manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d9663e2b-88be-4db7-9ea9-077877a6608f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TSC22D1', 'KLF1+MAP2K6', 'ctrl', ..., 'RHOXF2BB+SET', 'FOXA3',\n",
       "       'CELF2'], dtype='<U15')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "521b8819-6589-4acf-a8aa-ae84cef440b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = X_train[y_train == 'TSC22D1']\n",
    "diff_max_same = []\n",
    "for i in range(temp.shape[0]-1):\n",
    "    diff_max_same.append(np.max(abs(temp[i] - temp[i+1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8bdb9946-1f08-42c6-9cd8-dca7852247a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = X_train[y_train != 'TSC22D1']\n",
    "diff_max = []\n",
    "for i in range(min(temp2.shape[0]-1, temp.shape[0]-1)):\n",
    "    diff_max.append(np.max(abs(temp[i] - temp2[i+1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cd713acf-80b2-4c89-ba8d-7cb47caa0135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(diff_max_same, bins=50,alpha=0.5,density=True)\n",
    "plt.hist(diff_max, bins=50,alpha=0.5, density=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3d6d85-c909-43be-9845-e80618492b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
